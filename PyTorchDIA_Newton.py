"""PyTorch DIA - Master

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11j4rBN2RB4xsxjHNO5jvHYfgGZXBIAEe

**Brief description**

A GPU accelerated approach for fast kernel (and differential background) solutions. The model image proposed in the Bramich (2008) algorithm is analogous to a very simple CNN, with a single convolutional layer / discrete pixel array (i.e. the kernel) and an added scalar bias (i.e. the differential background). We do not solve for the discrete pixel array directly in the linear least-squares sense. Rather, by making use of PyTorch tensors (GPU compatible multi-dimensional matrices) and neural network architecture, we solve via an efficient gradient-descent directed optimisation.
"""
'''
from google.colab import drive
drive.mount('/content/drive')

# memory footprint support libraries/code
!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnÃ¢â‚¬â„¢t guaranteed
gpu = GPUs[0]
def printm():
 process = psutil.Process(os.getpid())
 print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " | Proc size: " + humanize.naturalsize( process.memory_info().rss))
 print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()
'''

import torch
import numpy as np
from astropy.io.fits import getdata
import matplotlib.pyplot as plt
from scipy.signal import convolve2d as conv
import time
from torch import autograd
import os
from scipy.signal import convolve2d
from astropy.stats import mad_std
from matplotlib.colors import LogNorm
from astropy.io import fits
from sklearn.feature_extraction.image import extract_patches_2d
from scipy.stats import norm


print('PyTorch version:', torch.__version__)
# make sure to enable GPU acceleration! (Tesla K80 GPU)
if torch.cuda.is_available() is True:
  device = 'cuda'
else:
  print('CUDA not available, defaulting to CPU')


def convert_to_tensor(image):
  if type(image) is np.ndarray:
      image = image.astype(np.float32)
      image = torch.tensor(image[None, None, :, :])
  else:
      pass

  return image


def infer_kernel(R, I, NM, i, init_kernel, init_B, maxiter, alpha, FIM, convergence_plots, d, ks, speedy, tol, lr_kernel, lr_B, SD_steps, Newton_tol):

    '''
    # Arguments
    * 'R' (numpy.ndarray or torch.tensor): The reference image
    * 'I' (numpy.ndarray or torch.tensor): The data/target image
    * 'NM' (numpy.ndarray or torch.tensor): The noise model 'image'
    * 'init_kernel' (torch.tensor): Initial guess for the PSF-matching kernel
    * 'init_B' (torch.tensor): Initial guess for the differential background parameter
    * 'i' (int): Iteration number i.e. M_i estimate

    # Keyword arguments
    * 'maxiter' (int): Maximum number of iterations for the optimisation
    * 'alpha' (float): Strength of the L2 regularisation penalty
    * 'FIM' (bool): Calculate parameter uncertanties from the Fisher Matrix
    * 'convergence_plots' (bool): Plot parameter estimates vs steps after optimising
    * 'd' (int): Polynomial of degree 'd' for fitting a spatially varying background
    * 'ks' (int): kernel of size ks x ks, needs to be odd
    * speedy (bool): If True, don't bother with linear transformation operation
      i.e. to be used if we're solving for a scalar background parameter
    * tol (float): Minimum relative change in parameter values before claiming convergence
    * lr_kernel (float): Steepest descent learning rate for kernel
    * lr_B (float): Steepest descent learning rate for background parameter(s)
    * SD_steps (int): Number of gradient descent steps to talke before switching to quasi-Newton optimisation
    
    # returns
    * 'kernel' (numpy.ndarray): the (flipped) inferred kernel
    * 'inferred_bkg' (float): B_0 background term
    * 'fit' (numpy.ndarray): the spatially varying background (inferred_bkg == fit if d=0)
    '''
    
    R, I, NM = convert_to_tensor(R), convert_to_tensor(I), convert_to_tensor(NM)
    
    if speedy is True:
      model = torch.nn.Sequential(
          torch.nn.Conv2d(in_channels=1,
                          out_channels=1,
                          kernel_size=ks,
                          padding = np.int((ks/2)-0.5),
                          padding_mode = 'zeros',
                          bias=True

        )
      )
      '''
      # Initialise kernel with unit gaussian
      kernel_psf_sigma = 1.
      init_kernel = np.exp(-0.5 * (np.arange(-np.int((ks/2)), np.int(ks/2)+1)[:, None] ** 2
              + np.arange(-np.int((ks/2)), np.int(ks/2)+1)[None, :] ** 2)/kernel_psf_sigma**2)
      init_kernel /= np.sum(init_kernel)
      init_kernel = convert_to_tensor(init_kernel)
      init_kernel = torch.add(init_kernel, torch.tensor(1e-3 * np.random.normal(size=init_kernel.shape)).float())
      model[0].weight = torch.nn.Parameter(init_kernel, requires_grad=True)
      '''
      # Initialise kernel and bias

      #model[0].weight = torch.nn.Parameter(1e-3*torch.ones(model[0].weight.shape, requires_grad=True))
      #model[0].bias = torch.nn.Parameter(1e-3*torch.ones(model[0].bias.shape, requires_grad=True))
      #print(model[0].weight.shape, model[0].bias.shape)
      #stop = input()
      
      model[0].weight, model[0].bias = init_kernel, init_B
    
    else:
      class model(torch.nn.Module):
          def __init__(self):

              super(model, self).__init__()
              self.conv = torch.nn.Conv2d(in_channels=1,
                              out_channels=1,
                              kernel_size=ks,
                              padding = np.int((ks/2)-0.5),
                              padding_mode = 'zeros',
                              bias=False)
              
              self.poly = torch.nn.Linear(2*d+1, 1, bias=False)
              #self.poly = torch.nn.Linear(500**2, 1, bias=False)
           
          def forward(self, x, A):
              reshaped_size = (1, 1, R[0][0][0].size()[0], R[0][0][0].size()[0])
              y_pred =  torch.add(self.conv(x), torch.reshape(self.poly(A), reshaped_size))
              return y_pred
    
      model = model()

      # Construct the design/weight matrix for the polynomial background fit
      x = np.linspace(-0.5, 0.5, R[0][0][0].size()[0])
      y = np.linspace(-0.5, 0.5, R[0][0][0].size()[0])
      X, Y = np.meshgrid(x, y, copy=False)
      X = X.flatten()
      Y = Y.flatten()
      
      if d == 0:
        A = np.array([X*0+1]).T
        def poly2Dreco(X, Y, c):
          return c[0]
      elif d == 1:
        A = np.array([X*0+1, X, Y]).T      
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2]
      elif d == 2:
        A = np.array([X*0+1, X, Y, X**2, Y**2]).T
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2] + X**2*c[3] + Y**2*c[4]
      elif d == 3:
        A = np.array([X*0+1, X, Y, X**2, Y**2, X**3, Y**3]).T
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2] + X**2*c[3] + Y**2*c[4] + X**3*c[5] + Y**3*c[6]
      else:
        print('Polynomial of d=%d not currenty supported... need to automate this, reverting to d=3' % d)
        A = np.array([X*0+1, X, Y, X**2, Y**2, X**3, Y**3]).T
        def poly2Dreco(X, Y, c):
          return c[0] + X*c[1] + Y*c[2] + X**2*c[3] + Y**2*c[4] + X**3*c[5] + Y**3*c[6]
      
      if torch.cuda.is_available() is True:
        A = torch.tensor(A).to(device).float()
      else:
        A = torch.tensor(A).float()

      
      # Initialise kernel weights + bias
      if i == 0:
          model.conv.weight = torch.nn.Parameter(1e-3* torch.ones(model.conv.weight.shape, requires_grad=True))
          model.poly.weight = torch.nn.Parameter(1* torch.ones(model.poly.weight.shape, requires_grad=True))
      else:
          model.conv.weight = init_kernel
          model.poly.weight = init_B
    
    # Move model to GPU
    if torch.cuda.is_available() is True:
      model = model.to(device)

    # Define the loss (our scalar objective function to optimise)
    # Sometimes referred to as the 'cost' in the ML literature
    class log_likelihood(torch.nn.Module):
    
        def forward(model, targ, NM, w):
            weights = torch.reciprocal(NM)
            lnp = -0.5 * torch.pow(weights*(model-targ), 2).sum()
            prior = - alpha*torch.abs(torch.sum(torch.pow(w, 2)))
            lnp += prior
            return lnp

    # Keep track of the speed to convergence for development's sake
    losses = []
    ts = []

    # keep track of parameters to check convergence
    if speedy is True:
      psf = []
      B0 = []
    else:
      psf = []
      bcoeffs = np.array((model.poly.weight.cpu().detach().numpy()))


    ## optimizers and learning rates ##
    if i > 1:
      #print('Decreasing SD learning rate for iteration %d by lr/(10)' % i)
      #lr_kernel = lr_kernel/(10**1)
      #lr_B = lr_B/(10**1)
      #print('Decreasing SD learning rate for iteration %d by lr/(%d+1)' % (i, i))
      #lr_kernel = lr_kernel/(10**i)
      #lr_B = lr_B/(10**i)
      print('Decreasing SD learning rate to default for Adam: 1e-3')
      lr_kernel, lr_B = 1e-3, 1e-3
  
    if speedy is True:
      optimizer_Adam = torch.optim.Adam([
                      {'params': model[0].weight, 'lr': lr_kernel},
                      {'params': model[0].bias, 'lr': lr_B}
                  ])
                  
      if i == 0:
          tol = tol
      else:
          tol = 1e-9    
      
      optimizer_Newton = torch.optim.LBFGS(model.parameters(), tolerance_change=tol, history_size=100, line_search_fn=None)
      
      def closure():
        #ts.append(t)
        optimizer_Newton.zero_grad()
        y_pred = model(R)
        loss = -log_likelihood.forward(y_pred, I, NM, model[0].weight)
        #losses.append(loss.detach().item())
        loss.backward()
        return loss
      
    else:
        # Optimize with the 'Adam' algorithm.
        # See https://arxiv.org/abs/1609.04747 for review + recommendations
        # of this and other gradient descent optimization algorithms
        # N.B. the choice of two different learning rates for the bias and
        # and convolutional layer
        # for LI use 1e-3 and 1 respectively
        # for Sinistro use 5e-2 and 500
        

        optimizer_Adam = torch.optim.Adam([
                    {'params': model.conv.weight, 'lr': lr_kernel},
                    {'params': model.poly.weight, 'lr': lr_B}
                ])
                
        optimizer_Newton = torch.optim.LBFGS(model.parameters(), tolerance_change=tol, history_size=100, line_search_fn=None)
        
        def closure():
            #ts.append(t)
            optimizer_Newton.zero_grad()
            y_pred = model(R, A)
            loss = -log_likelihood.forward(y_pred, I, NM, model.conv.weight)
            #losses.append(loss.detach().item())
            loss.backward()
            return loss
    # Time the optimisation
    start_time_infer = time.time()

    # flag to switch to quasi newton step
    use_Newton = False
    
    # NB Use .detach().item() to clear graph and free memory while appending to lists
    for t in range(maxiter):
    
        if t < SD_steps and use_Newton == False:
          if speedy is True:
            y_pred = model(R)
            loss = -log_likelihood.forward(y_pred, I, NM, model[0].weight)
          else:
            y_pred = model(R, A)
            loss = -log_likelihood.forward(y_pred, I, NM, model.conv.weight)
        
          losses.append(loss.detach().item())
          ts.append(t)
          optimizer_Adam.zero_grad()
          loss.backward()
          optimizer_Adam.step()
        
        else:
          optimizer_Newton.step(closure)

        if speedy is True:
          psf.append(torch.sum(model[0].weight).detach().item())
          B0.append(model[0].bias.detach().item())
        else:          
          psf.append(torch.sum(model.conv.weight).detach().item())
          bcoeffs = np.vstack((bcoeffs, model.poly.weight.cpu().detach().numpy()))

        # Convergence reached if less than specified tol
        if speedy is True:
          if t>1 and abs((psf[-1] - psf[-2])/psf[-2]) < tol and abs((B0[-1] - B0[-2])/B0[-2]) < tol:
            print(psf[-1], B0[-1])
            print("'Speedy' convergence reached!")
            break
          elif t>1 and abs((psf[-1] - psf[-2])/psf[-2]) < Newton_tol and abs((B0[-1] - B0[-2])/B0[-2]) < Newton_tol and use_Newton == False:
            print('Switching to Quasi-Newton step')
            use_Newton = True

        else:
          if t>1 and abs((psf[-1] - psf[-2])/psf[-2]) < tol:
            converge = []
            for bd in range(0, 2*d+1):
              if abs((bcoeffs[:,bd][-1]-bcoeffs[:,bd][-2])/bcoeffs[:,bd][-2]) < tol:
                converge.append(1)
              elif use_Newton == False:
                Newton = []
                for bd in range(0, 2*d+1):
                  if abs((bcoeffs[:,bd][-1]-bcoeffs[:,bd][-2])/bcoeffs[:,bd][-2]) < Newton_tol:
                    Newton.append(1)
                    
                if len(Newton) == 2*d+1:
                    print('Switching to Qausi-Newton step')
                    use_Newton = True
                    
              else:
                  continue
            
            if len(converge) == 2*d+1:
              print('Convergence reached!')
              break

                            
                    

    time_to_kernel_solution = time.time() - start_time_infer
    print("--- Finished kernel and background fit in %s seconds ---" % time_to_kernel_solution)
    #print("Loss:", loss.item())

    if speedy is True:
      kernel, B = model[0].weight, model[0].bias
      # and output the non-flipped kernel (and B with same naming convention to initialise optimisation for the next iteration
      kernel_guess, B_guess = model[0].weight, model[0].bias
    else:
      kernel = model.conv.weight
      B = model.poly.weight
      kernel_guess, B_guess = model.conv.weight, model.poly.weight

    print(B)

    def compute_full_hessian(grads):

      #Note the use of .detach(). In general, computations involving
      #variables that require gradients will keep history.

      grads = torch.cat((grads[0].flatten(), grads[1].flatten()))
      grad = grads.reshape(-1)
      d = len(grad)
      H = torch.zeros((d, d))
      
      t = time.time()
      print('Looping...')
      for i,dl_dthetai in enumerate(grads):
        H_rowi = torch.autograd.grad(dl_dthetai, model.parameters(), retain_graph=True)
        H_rowi = torch.cat((H_rowi[0].flatten(), H_rowi[1].flatten()))
        H[i] = H_rowi.detach()
      print('Looping took %s seconds' % (time.time() - t))
      return H


    def compute_hessian_blockdiags(grads, params):
      H = []
      t = time.time()
      print('Looping...')
      for i, (grad, p) in enumerate(zip(grads, params)):
          grad = grad.reshape(-1)
          d = len(grad)
          dg = torch.zeros((d, d))

          for j, g in enumerate(grad):
              g2 = autograd.grad(g, p, create_graph=True)[0].view(-1)
              dg[j] = g2.detach()

          H.append(dg)
      print('Looping took %s seconds' % (time.time() - t))
      return H

    
    if FIM == True:
      '''
      We're minimizing an approximation to the negative log-likelihood
      So the returned Hessian is equivalent to the observed Fisher
      Information Matrix (i.e. FIM evaluated at MLE)
      '''

      def det_test(matrix):
        sign, logdet = torch.slogdet(matrix)
        if sign.item() <= 0.:
          print('Covariance matrix not positive definite! Sign of determinant:', sign.item())
        elif sign.item() > 0.:
          pass

      def eigenvals_test(matrix):
        eigenvals = torch.eig(matrix)[0]
        if any(eigval <= 0. for eigval in eigenvals[:,0]):
          print('Covariance matrix not positive definite!. Non-positive eigenvalues.1')

      
      def get_stderror(obs_fisher_matrix):
        '''
        Is the estiamted covariance matrix valid?
        A valid covariance matrix has to be positive definite
        Test 1:
        check if det cov_matrix <= 0., cov_matrix is not valid
        Test 2:
        diagnoalise cov_matrix to determine eigenvalues.
        If any of these are <= 0., cov_matrix is not valid
        '''
        cov_matrix = torch.inverse(obs_fisher_matrix)
        det_test(cov_matrix) # Test 1
        eigenvals_test(cov_matrix) # Test 2
        cov_matrix_diagonals = torch.diag(cov_matrix)

        return cov_matrix_diagonals
      '''
      Compute FIM (i.e. Hessian!)
      '''
      '''
      # Block diagonals #
      y_pred = model(R, A)
      loss = -log_likelihood.forward(y_pred, I, NM, model.conv.weight)
      logloss_grads = autograd.grad(loss, model.parameters(), create_graph=True, retain_graph=True)
      print('Building block diag Hessian...')
      block_diag_hessian_time = time.time() 
      H = compute_hessian_blockdiags(logloss_grads, model.parameters())
      print('---Finished constructing block diag in %s seconds---' % (time.time() - block_diag_hessian_time))
      H_kernel, H_B0 = H[0], H[1]
      psf_err, B0_err = torch.sqrt(torch.sum(get_stderror(H_kernel))), torch.sqrt(get_stderror(H_B0))
      print('Photometric scaling:', torch.sum(model.conv.weight), '+/-', psf_err.item())
      print('B_0:', torch.sum(model.poly.weight[0][0]), '+/-', B0_err.item())
      '''
      
      # Full Hessian #
      if speedy is True:
        y_pred = model(R)
      else:
        y_pred = model(R, A)
      loss = -log_likelihood.forward(y_pred, I, NM, kernel)
      logloss_grads = autograd.grad(loss, model.parameters(), create_graph=True, retain_graph=True)
      print('Building full Hessian...')
      full_hessian_time = time.time() 
      H = compute_full_hessian(logloss_grads)

      print('---Finished constructing full hessian in %s seconds---' % (time.time() - full_hessian_time))      
      cov_matrix_diags = get_stderror(H)
      psf_err, B0_err = torch.sqrt(torch.sum(cov_matrix_diags[0:-(2*d+1)])), torch.sqrt(cov_matrix_diags[-(2*d+1)])
      print('Photometric scaling:', torch.sum(kernel).item(), '+/-', psf_err.item())
      if speedy is True:
        print('B_0:', torch.sum(B[0]).item(), '+/-', B0_err.item())
      else:
        print('B_0:', torch.sum(B[0][0]).item(), '+/-', B0_err.item())


    else:
      print('Photometric scaling:', torch.sum(kernel))
      if speedy is True:
        print('B_0:', torch.sum(B[0]).item())
      else:
        print('B_0:', torch.sum(B[0][0]).item())
 
    if convergence_plots == True:
      plt.plot(ts[1:], np.log(losses[1:]))
      plt.xlabel('Iterations')
      plt.ylabel('log_10(loss)')
      plt.title('log loss vs iterations')
      plt.show()
    
      print('This version does not print parameter values vs iterations yet!')
      '''
      plt.plot(ts[1:], psf[1:])
      plt.xlabel('Iterations')
      plt.ylabel('psf')
      plt.title('psf vs iterations')
      plt.show()


    
      if speedy is True:
        plt.plot(ts[1:], (B0[1:]))
        plt.xlabel('Iterations')
        plt.ylabel('B_0')
        plt.title('B_0 vs iterations')
        plt.show()
      else:
        for c in range(0, 2*d+1):
          plt.plot(ts, bcoeffs[:,c][1:])
          plt.xlabel('Iterations')
          plt.ylabel('B_%d' % c)
          plt.show()
    '''
    # flip kernel to correct orientation (as I pass this to conv2d)
    kernel = torch.flip(kernel, [2, 3])
    kernel = kernel[0][0].cpu().detach().numpy()
    B = B[0].cpu().detach().numpy()

    if speedy is True:
      B = B.item()

    if d>0:
      X, Y = np.meshgrid(x, y, copy=False)
      B = poly2Dreco(X, Y, B)
    
    return kernel, B, kernel_guess, B_guess, time_to_kernel_solution




def DIA(R_full,
        I_full,
        flat,
        read_noise = 0.,
        tot_im = 1.,
        unweighted=False,
        n_samples=1,
        full_image=True,
        display_stamps=False, 
        sky_subtract = False,
        iters=3,
        ks = 15,
        lr_kernel = 1e-2,
        lr_B = 1e1,
        SD_steps = 100,
        Newton_tol = 1e-6,
        poly_degree=0,
        fast=True,
        tol = 1e-5,
        alpha = 0., 
        max_iterations = 5000,
        fisher=False,
        show_convergence_plots=False,
        display_D=False,
        k=5,
        precision=3,
        display_masked_stamps=False,
        display_M=False,
        display_kernel=False,
        display_B = False):
  
  '''
  ## Arguments
  * 'R_full' (numpy.ndarray): Input reference image
  * 'I_full'(numpy.ndarray): Input target image
  * 'flat' (numpy.ndarray): provided flat field for the images

  ## Keyword Arguments
  * 'read_noise' (float): detector read noise (ADU), defeault = 0.
  * 'unweighted' (bool): don't bother with a noise model, default=False
  * 'n_samples' (int): If MC sampling, specify how many kernel and background solutions we want, default = 1
  * 'full_image' (bool): Infer kernel for full image or MC sampled subregions, default=True
  * 'display_stamps' (bool): Plot the input reference and target pair (either full image or subregions), default=False
  * 'sky_subtract' (bool): Subtract the median pixel values from the input images, default=False
  * 'iters' (int): Number of iterations (estimates of Model image) to perform, default = 3
  * 'ks' (int): Size of ks x ks kernel **Needs to be odd**, default=15
  * 'lr_kernel' (float): The learning rate for the parameters of the convolution kernel, default=1e-2
  * 'lr_B' (float): The learning rate for the parameters for the differential background solution, default=1e1
  * 'SD_steps' (int): Number of gradient descent steps to talke before switching to quasi-Newton optimisation
  * 'poly_degree' (int): Degree of polynomial for background fit, default=0
  * 'fast' (bool): Use in-built torch.nn.Conv2d function if True, which fits for a scalar background term.
     If False, we'll fit a polynomial of degree 'poly_degree' for the background, which requires an additional
     customised linear transformation operation, which is slower than the in-built function even for 0 degree
     polynomial, default = True.
  * 'tol' (float): Minimum relative change in parameters for claiming convergence of kernel and background fit,
     default = 1e-5
  * 'alpha' (float): Strength of L2 regularisation penalty on kernel solution, default = 0.
  * 'max_iterations' (int): Maximum number of iterations in optimisation, default=5000
  * 'fisher' (bool): Output kernel and background uncertainty estimates calculated from Fisher Matrix, default=False
  * 'show_convergence_plots' (bool): Plot parameter estimates vs steps in optimisation procedure, default=False
  * 'display_D' (bool): Plot the difference image(s), default = False
  * 'k' (int): sigma clip to apply to normalised residuals at each iteration,
     default=5 **WARNING:Highly sensitve to choice of noise model!!
     If you're not sure, set this to be very large to avoid overly severe clipping!**
  * 'precision' (int): Decimal place precision at which we claim convergence of kernel solution,
     default=3 i.e. if change in photometric scale factor at next iteration < 0.001 we've converged
  * 'display_masked_stamps' (bool): Plot the sigma clipped images, default=False
  * 'display_M' (bool): Plot the model image(s)
  * 'display_kernel' (bool): Plot the inferred kernel(s)
  * 'display_B* (bool): Plot the inferred spatially varying background(s)
  
  ## Returns
  * 'kernel' (numpy.ndarray): the convolution kernel
  * 'B' (numpy.ndarray): the differential background
  '''
  solve_times = []

  ####### Sample sub-images from R and I for empirical error estimation ######

  psf_samples = []
  B_samples = []
  psf_samples1 = []
  B_samples1 = []

  start_time_total = time.time()

  #n_samples = 1 # odd number so can take median psf and corresponding B0
  if full_image == False:
    stamp_sizes = np.random.randint(low=4*ks, high=np.int(R_full.shape[0]/4), size=n_samples)
    #stamp_sizes = np.random.randint(low=4*ks, high=R_full.shape[0], size=n_samples)
    seeds = np.random.randint(low=0, high=1e9, size=n_samples)

  # Correlations with patch size?
  patch_sizes = []

  for sample in range(0, n_samples):
    print('\nSample:', sample)

    if full_image == True:
      R = R_full
      I = I_full
      
    else:

      patch_R = extract_patches_2d(R_full, (stamp_sizes[sample], stamp_sizes[sample]), 1, random_state = seeds[sample])
      patch_I = extract_patches_2d(I_full, (stamp_sizes[sample], stamp_sizes[sample]), 1, random_state = seeds[sample])
      R = patch_R[0]
      I = patch_I[0]

      print('Stamp size:', R.shape)

    # sky subtract
    # hold on to sky level to add back into estimate of noise model
    if sky_subtract is True:
      print("Subtracting median 'sky' level from images")
      sky_np = np.median(I)
      R -= np.median(R)
      I -= np.median(I)
    else:
      print("Not subtracting sky prior to kernel solution")
      sky_np = 0.


    # Hold sky subtracted copies in memory to be used later
    R_0 = np.copy(R)
    I_0 = np.copy(I)
    
    if display_stamps == True:
      plt.figure(figsize=(5,5))
      f, axarr = plt.subplots(1,2)
      f.set_figheight(8)
      f.set_figwidth(8)
      axarr[0].imshow(R, origin='lower')
      axarr[1].imshow(I, origin='lower')
      plt.show()
    
    if unweighted == True:
      NM = np.ones((I.shape[0], I.shape[1]))
    else:
      # Construct noise model for first iteration
      #NM_var = I + read_noise**2 + sky_np
      
      ## EMCCD noise model from DM Bramich's IDL code ##
      sigma0 = 2.55 # read noise
      N = tot_im # number of images
      gain_CCD = 25.8 # CCD gain
      gain_EM = 300. # EM gain
      G = gain_CCD / gain_EM # Total gain
      excess_noise_factor = 2 # EMCCD fudge factor
      #shot_noise = M/(G*flat)
      shot_noise = I/(G*flat)
      #read_noise = N*sigma0**2 / flat**2
      #read_noise = N*sigma0**2 / (gain_EM*flat**2)
      #var_M = excess_noise_factor*shot_noise + read_noise
      print('Just shot noise in noise model...')
      var_M = excess_noise_factor*shot_noise
      NM = np.sqrt(var_M) # Noise Model
      
      # Hack! Can't have sqrt of negatives, and avoid division by zero
      #NM_var[np.where(NM_var < 0)] = 1e-6
      #NM = np.sqrt(NM_var)

    #### bad pixel mask

    mask = np.zeros(NM.shape)


    #### Convert numpy images to tensors and move to GPU
    I, R, NM = convert_to_tensor(I), convert_to_tensor(R), convert_to_tensor(NM)

    start_time_load2gpu = time.time()
    # Move to GPU
    if torch.cuda.is_available() is True:
      R = R.to(device)
      I = I.to(device)
      NM = NM.to(device)

      if n_samples == 1 and full_image == True:
        print("--- Time to move data onto GPU: %s ---" % (time.time() - start_time_load2gpu))

    # Iteratively update noise model and apply image masks
    noise_models = []
    out_models = []

    # Store to assess convergence
    photometric_scale_factor = []

    for i in range(0, iters):
        
        if i > 0:
            M = np.array(noise_models[i-1])
            # Hack!
            if np.any(M < 0.):
              print('Warning: Negatives in M!')
              print('Yer data violates the model!!')
              M = np.abs(M)

            if unweighted == True:
              NM = np.ones((I.shape[0], I.shape[1]))
            else:
              '''
              ## CCD noise model for synthetic images ##
              ## F_ij = 1, G = 1 ##
              shot_noise = M
              noise_var = read_noise**2 + shot_noise
              NM = np.sqrt(noise_var)
              '''
              '''
              # Fit quality metrics
              N_data = len(I.flatten())
              # 1) Mean Squared Error
              MSE = 1./(N_data) * np.sum((M - I_0)**2)
              # 2) Mean Fit Bias
              MFB = 1./(N_data) * np.sum((I_0 - M)/sigma_I)
              # 3) Mean Fit Variance
              MFV = 1./(N_data - 1) * np.sum((((I_0 - M)/sigma_I) - MFB)**2)
              print('MSE', MSE)
              print('MFB', MFB)
              print('MFV', MFV)
              '''
              
              ## EMCCD noise model from DM Bramich's IDL code ##
              sigma0 = 2.55 # read noise
              N = tot_im # number of images
              gain_CCD = 25.8 # CCD gain
              gain_EM = 300. # EM gain
              G = gain_CCD / gain_EM # Total gain
              excess_noise_factor = 2 # EMCCD fudge factor
              shot_noise = M/(G*flat)
              #read_noise = N*sigma0**2 / flat**2
              #read_noise = N*sigma0**2 / (gain_EM*flat**2)
              #var_M = excess_noise_factor*(shot_noise + read_noise)
              #print('Photon var sum:', np.sum(excess_noise_factor*shot_noise))
              #print('Read var sum:', np.sum(read_noise))
              #read_noise = 0.
              #var_M = excess_noise_factor*shot_noise + read_noise
              print('Just shot noise in noise model...')
              var_M = excess_noise_factor*shot_noise
              NM = np.sqrt(var_M) # Noise Model
              
            
            R, I = R_0, I_0

            # D for clipping outliers
            #D = (M - sky_np) - I # Take out additive sky noise from M i.e. current estimate of 'noise model'
            #D_std = np.std(D)
            D = (I + sky_np) - M

            if display_D == True:
              plt.imshow(D, origin='lower')
              plt.colorbar()
              plt.show()
              print('Median ADU in D:', np.median(D))

            # Normalised residuals e_ij = (M_ij- I_ij)/NM_ij
            # sigma clipping employed where abs(epsilon_ij)>=k
            epsilon = D/NM

            print('Sum abs(norm_resids):', np.sum(np.abs(epsilon)))

            # Apply 'mask'
            # Below assumes epsilon is a good approximation to a gaussian
            mask[np.where(np.abs(epsilon)>k)] = 1
            NM[np.where(mask == 1)] = 1e99
            print('\nNumber of masked pixels:', np.sum(mask))

            if display_masked_stamps == True:
              # Display masked R and I
              #plt.figure(figsize=(5,5))
              #f, axarr = plt.subplots(1,2)
              #f.set_figheight(8)
              #f.set_figwidth(8)
              #axarr[0].imshow(R)
              #axarr[1].imshow(I)
              #plt.show()

              plt.figure(figsize=(5,5))
              plt.hist(epsilon.flatten(), bins='auto', density=True)
              #x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)
              x = np.linspace(-5, 5, 100)
              plt.plot(x, norm.pdf(x, 0, 1))
              plt.xlim(-5, 5)
              plt.xticks(fontsize=20)
              plt.yticks(fontsize=20)
              plt.xlabel('Normalised residuals', fontsize=20)
              plt.ylabel('Probability', fontsize=20)
              #plt.savefig(os.path.join(path, 'NormalisedResids.png'), bbox_inches='tight', overwrite=True)
              plt.show()
            
            #### Convert numpy images back to tensors and move to GPU
            I, R, NM = convert_to_tensor(I), convert_to_tensor(R), convert_to_tensor(NM)
            if torch.cuda.is_available() is True:
              I, R, NM = I.to(device), R.to(device), NM.to(device)
              
              
              
            #model[0].weight = torch.nn.Parameter(1e-3*torch.ones(model[0].weight.shape, requires_grad=True))
            #model[0].bias = torch.nn.Parameter(1e-3*torch.ones(model[0].bias.shape, requires_grad=True))
              
        '''
        To do: Initialise with prior estimate of kernel and B if i>0
        '''
        ### Initialise kernel and B parameters with previous guess
        if i == 0:
          kernel_shape = (1, 1, ks, ks)
          B_shape = (1)
          init_kernel = torch.nn.Parameter(1e-3*torch.ones(kernel_shape, requires_grad=True))
          init_B = torch.nn.Parameter(1e-3*torch.ones(B_shape, requires_grad=True))
        else:
          init_kernel, init_B = kernel_guess, B_guess


        kernel, B, kernel_guess, B_guess, time_to_solution = infer_kernel(R, I, NM, i, init_kernel, init_B, 
                                                             maxiter=max_iterations,
                                                             alpha=alpha,
                                                             FIM=fisher,
                                                             convergence_plots=show_convergence_plots,
                                                             d = poly_degree,
                                                             ks = ks,
                                                             speedy = fast,
                                                             tol = tol,
                                                             lr_kernel = lr_kernel,
                                                             lr_B = lr_B,
                                                             SD_steps = SD_steps,
                                                             Newton_tol = Newton_tol)
                                                             
        solve_times.append(time_to_solution)

        if display_kernel == True:
          plt.imshow(kernel, origin='lower')
          plt.show()

        R, I = R_0, I_0
        M = convolve2d(R, kernel, mode='same') + B

        if display_M == True:
          plt.imshow(M, origin='lower')
          plt.show()
               
        noise_models.append(M + sky_np) # ADD SKY BACK IN ORDER TO TAKE SQRT

        ## Convergence within 'precision' decimal places
        photometric_scale_factor.append(np.round(np.sum(kernel), precision))

        # append coeff estimates on first iteration for comparison with third (below)
        if i == 0:
            psf_samples1.append(np.sum(kernel))
            B_samples1.append(B)
        #if i>0 and photometric_scale_factor[i] == photometric_scale_factor [i-1]:
        if i == iters - 1:
            psf_samples.append(np.sum(kernel))
            B_samples.append(B)
            patch_sizes.append(R.shape[0])
            print('Photometric Scale Factor:', np.sum(kernel))
            try: # if speedy is True, we solve for B differently, so just ignore the shape for now with this exception
              if B.shape != (1,) and display_B == True:
                plt.title('B fit')
                plt.imshow(B, origin='lower')
                plt.colorbar()
                plt.show()
              elif B.shape == (1,):
                print('B_0:', B)
            except AttributeError:
              pass
            print('Converged in %d iterations' % np.int(i+1))
            break
        #elif i == iters - 1 and photometric_scale_factor[i] != photometric_scale_factor [i-1]:
        #    print('Convergence not reached, skipping....')
        #    continue

  total_time = time.time() - start_time_total
  print("--- Finished in a total of %s seconds ---" % total_time)

  #return psf_samples, B_samples, patch_sizes# psf_samples1, B_samples1, patch_sizes
  return kernel, B, np.sum(solve_times), total_time, mask






