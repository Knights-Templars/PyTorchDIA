{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section 5.1 - Real (EMCCD) Image Speed Tests",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOm4hO6dDGwMA9xqEFNFt8v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jah1994/PyTorchDIA/blob/master/Section_5_1_Real_(EMCCD)_Image_Speed_Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwe-I1VxZAwV"
      },
      "source": [
        "This notebook runs the speed tests on real EMCCD images in Section 5.1 of the PyTorchDIA manuscript."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msq5QiQKw95Y"
      },
      "source": [
        "## CPU specs ##\n",
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix4SqSawxU3K"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWMJFjcQN7Sp"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RcbiMzFOG8D"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAKDgZV8OJru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26019a50-5390-4014-ad84-d1d64e5488db"
      },
      "source": [
        "#############################################\n",
        "## required to import custom modules in GC ##\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/PyTorchDIA - Speed tests')\n",
        "##############################################\n",
        "\n",
        "# grab photutils\n",
        "#!pip install photutils\n",
        "\n",
        "# other useful imports\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from astropy.io.fits import getdata\n",
        "import time\n",
        "from scipy.signal import convolve2d\n",
        "from scipy.ndimage.interpolation import shift\n",
        "from scipy.stats import norm\n",
        "import PyTorchDIA_EMCCD\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ1PDV3UOVu4"
      },
      "source": [
        "## load images, reference and master flat ##\n",
        "## this can take a while in colab\n",
        "\n",
        "def load_cropped_images(path, crop):\n",
        "\n",
        "  ## reference\n",
        "  ref_file = os.path.join(path, 'coll_LOB190560Z_Llr_2019-05-14_00129.fits')\n",
        "  ref_data = getdata(ref_file, header=True)\n",
        "  ref, ref_fwhm = ref_data[0], ref_data[1]['FWHM']\n",
        "\n",
        "  ## master flat\n",
        "  flat_file = os.path.join(path, 'master_flat.fits')\n",
        "  master_flat = getdata(flat_file, 0, header=True)[0]\n",
        "\n",
        "  ## shifts\n",
        "  shift_info = os.path.join(path, 'LOB190560Z_Shifts.txt')\n",
        "  shifts = np.genfromtxt(shift_info, delimiter=\"\\t\", dtype=str) # filename | xs | ys\n",
        "\n",
        "  ## crop reference and master flat ##\n",
        "  ref = ref[crop:ref.shape[0]-crop, crop:ref.shape[1]-crop]\n",
        "  #master_flat = master_flat[crop:master_flat.shape[0]-crop, crop:master_flat.shape[1]-crop]\n",
        "\n",
        "  ## ensure dtype=np.float32\n",
        "  ref = np.array(ref, dtype=np.float32)\n",
        "  master_flat = np.array(master_flat, dtype=np.float32)\n",
        "\n",
        "  fnames = []\n",
        "  images = []\n",
        "  FWHMs = []\n",
        "  N_images = []\n",
        "\n",
        "  for image_file in glob.glob(os.path.join(path, \"*coll*\")):\n",
        "    # avoid reference\n",
        "    if ref_file not in image_file:\n",
        "      fnames.append(image_file.split('/')[-1])\n",
        "      print(image_file.split('/')[-1])\n",
        "      image_data = getdata(image_file, header=True)\n",
        "      image, header = image_data[0], image_data[1]\n",
        "      image = image[crop:image.shape[0]-crop, crop:image.shape[1]-crop]\n",
        "      ## apply any crops to image border ##\n",
        "      images.append(image)\n",
        "      FWHMs.append(header['FWHM'])\n",
        "      N_images.append(header['TOT_IM'])\n",
        "\n",
        "  # convert to numpy arrays (float32)\n",
        "  images, FWHMs = np.array(images, dtype=np.float32), np.array(FWHMs)\n",
        "\n",
        "  print(ref.shape, master_flat.shape, images.shape)\n",
        "  print('Max x shift:', np.max(shifts[:,2].astype(float)))\n",
        "  print('Max y shift:', np.max(shifts[:,1].astype(float)))\n",
        "  print(np.median(FWHMs))\n",
        "\n",
        "  return images, FWHMs, N_images, fnames, shifts, ref, master_flat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R80lNlyPnBws"
      },
      "source": [
        "def extend_image_hw(image, kernel_size):\n",
        "    image_extended = np.zeros((np.shape(image)[0] + kernel_size - 1,\n",
        "                             np.shape(image)[1] + kernel_size - 1))\n",
        "    hwidth = np.int((kernel_size - 1) / 2)\n",
        "    image_extended[hwidth:image_extended.shape[0]-hwidth,\n",
        "                   hwidth:image_extended.shape[1]-hwidth] = np.array(image, float)\n",
        "    return image_extended\n",
        "\n",
        "def model_image(R, kernel, B0):\n",
        "    model = convolve2d(R, kernel, mode='same') + B0\n",
        "    return model\n",
        "\n",
        "def plot_normalised_residuals(epsilon):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.hist(epsilon.flatten(), bins='auto', density=True)\n",
        "    x = np.linspace(-5, 5, 100)\n",
        "    plt.plot(x, norm.pdf(x, 0, 1))\n",
        "    plt.xlim(-5, 5)\n",
        "    plt.xticks(fontsize=20)\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.xlabel('Normalised residuals', fontsize=20)\n",
        "    plt.ylabel('Probability', fontsize=20)\n",
        "    plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UGBx4nDRT20"
      },
      "source": [
        "## path to images\n",
        "path = '/content/drive/My Drive/PyTorchDIA - Speed tests/LOB190560Z_CollapsedFrames'\n",
        "\n",
        "# kernel and image sizes to test performance of optimisation of the robust loss function\n",
        "#kernel_size = [19, 25]\n",
        "crops = [150, 100, 50, 15]\n",
        "kernel_size = [19]\n",
        "\n",
        "for ks in kernel_size:\n",
        "\n",
        "  print('\\nKernel size:', ks)\n",
        "\n",
        "  for crop in crops:\n",
        "\n",
        "    print('Crop:', crop)\n",
        "\n",
        "    # load cropped images\n",
        "    images, FWHMs, N_images, fnames, shifts, ref, master_flat = load_cropped_images(path, crop)\n",
        "\n",
        "    # 'sky' subtract the reference\n",
        "    ref_sky = np.median(ref)\n",
        "    print('Sky level [ADU]:', ref_sky)\n",
        "    ref -= ref_sky\n",
        "\n",
        "    # information to output to record\n",
        "    times_to_kernel_solution = []\n",
        "    total_times = []\n",
        "    image_FWHMs = []\n",
        "    image_SNRs = []\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "\n",
        "\n",
        "        out_file_name = 'RealImageSpeedTest_' + str(512 - 2*crop) + '_' + str(ks) + '.txt'\n",
        "        print('Results recorded in:', out_file_name)\n",
        "\n",
        "        print('\\nImage %d of %d' % (i, len(images)))\n",
        "        print('FWHM:', FWHMs[i])\n",
        "        print('N images:', N_images[i])\n",
        "\n",
        "        # align flat with data image\n",
        "        # data images were aligned to the reference with an integer pixel shift, avoiding resampling\n",
        "        # this is fine for the small 45x45 arcseconds^2 FoV for the Danish LI camera\n",
        "        file_name = fnames[i]\n",
        "        xs, ys = shifts[:,1][np.where(shifts[:,0] == file_name)][0], shifts[:,2][np.where(shifts[:,0] == file_name)][0]\n",
        "        print('Aligning flat with (xs, ys) shifts:',xs.astype(int), ys.astype(int))\n",
        "        flat = shift(master_flat, (ys.astype(int),xs.astype(int)), order=0, cval=0.) # integer shift, order=0\n",
        "        flat = flat[crop:flat.shape[0]-crop, crop:flat.shape[1]-crop]\n",
        "\n",
        "        t0 = time.time()\n",
        "        \n",
        "        # infer kernel via robust PyTorchDIA code\n",
        "        print('\\n(Robust) PyTorchDIA solution')\n",
        "        SD_steps = 25000\n",
        "        kernel, B0 = PyTorchDIA_EMCCD.DIA(ref,\n",
        "                                          image,\n",
        "                                          flat,\n",
        "                                          read_noise = 0.,\n",
        "                                          ks = ks,\n",
        "                                          lr_kernel = 1e-3,\n",
        "                                          lr_B = 1e1,\n",
        "                                          SD_steps = SD_steps,\n",
        "                                          Newton_tol = 1e-6,\n",
        "                                          poly_degree=0,\n",
        "                                          fast=True,\n",
        "                                          tol = 1e-9,\n",
        "                                          max_iterations = SD_steps,\n",
        "                                          fisher=False,\n",
        "                                          show_convergence_plots=True)\n",
        "\n",
        "        total_time = time.time() - t0\n",
        "        \n",
        "        # SNR calculation\n",
        "        # compute model\n",
        "        ext_ref = extend_image_hw(ref, ks)\n",
        "        ext_M = model_image(ext_ref, kernel, B0)\n",
        "        hwidth = np.int((ks - 1) / 2)\n",
        "        M = ext_M[hwidth:ext_M.shape[0]-hwidth, hwidth:ext_M.shape[1]-hwidth] \n",
        "\n",
        "        # compute pixel uncertanties\n",
        "        gain_CCD = 25.8 # CCD gain\n",
        "        gain_EM = 300. # EM gain\n",
        "        G = gain_CCD / gain_EM # Total gain\n",
        "        excess_noise_factor = 2 # EMCCD fudge factor\n",
        "        shot_noise = M/(G*flat)\n",
        "        var_model = excess_noise_factor*shot_noise\n",
        "        pixel_uncertainties = np.sqrt(var_model) # Noise Model\n",
        "\n",
        "        # compute normalised residuals\n",
        "        D = image - M\n",
        "        epsilon = D / pixel_uncertainties\n",
        "        #plot_normalised_residuals(epsilon)\n",
        "\n",
        "        sky = np.median(image)\n",
        "        SNR = np.sum(image - sky) / np.sqrt(np.sum(pixel_uncertainties**2))\n",
        "        print('SNR:', SNR)\n",
        "\n",
        "        # image parameter info\n",
        "        image_FWHMs.append(FWHMs[i]) \n",
        "        image_SNRs.append(SNR)\n",
        "        \n",
        "        # time to solution\n",
        "        total_times.append(total_time)\n",
        "\n",
        "    # summary stats\n",
        "    print(len(total_times), len(image_FWHMs), len(image_SNRs))\n",
        "    print('Median solution time:', np.median(total_times))\n",
        "    print('Median FWHM:', np.median(image_FWHMs))\n",
        "    print('Median SNR:', np.median(image_SNRs))\n",
        "\n",
        "    # write to file\n",
        "    out = np.vstack((total_times, image_FWHMs, image_SNRs)).T\n",
        "    print('Output file shape:', out.shape)\n",
        "    np.savetxt(os.path.join(path, out_file_name), out)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqS37Mm53szb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}